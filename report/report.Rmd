---
title: "titanic_report"
author: "Alp Gunsever"
date: "13/01/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## 1 - Introduction 

This is a data analysis report intended to test bayesian data analysis skills using the titanic dataset from kaggle.

```{r libraries}
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
library(shinystan)
library(stringr)
library(corrplot)
library(projpred)
library(bayesplot)
library(mice)
library(VIM)
library(ggplot2)
theme_set(bayesplot::theme_default(base_family = "sans"))
library(dplyr)
library(gridExtra)
library(rstanarm)
library(brms)
```

## 2- Exploratory Data Analysis

We are first going to make an exploratory analysis on the data available at hand. We format the data beforehand in both training and test sets.

The existing observations for different predictors will be formatted into data structures that can be handled by R in a meaningful way. 

```{r clean data}
# read train and test data
dir <- file.path("C:","Users","alpgu","Dropbox","Data Science","Bayesian Data Analysis","BDA3 (Gelman)","titanic","data")
dat.train <- read.csv(file.path(dir,"train.csv"))
dat.test <- read.csv(file.path(dir,"test.csv"))

# combine train and test data for cleaning
dat.train_without_survival <- cbind(data.frame(PassengerId=dat.train[,1]),dat.train[,3:length(colnames(dat.train))])
dat.full <- rbind(dat.train_without_survival, dat.test)

# adjustments on data set

# factorize Pclass variable
dat.full$Pclass <- as.factor(dat.full$Pclass)

# extract titles from names
dat.full$title <- str_split_fixed(as.character(str_split_fixed(dat.full$Name, ",", 2)[,2]),". ",2)[,1]
dat.full$title <- gsub(" ", "", dat.full$title, fixed = TRUE)
dat.full$title[760] <- "Countess"
for (i in 1:length(dat.full$title)){
  if(grepl("Mr|Mrs|Miss|Master",dat.full$title[i]) == F){
    if(grepl("Countess|Sir|Lady|Don",dat.full$title[i]) == T){
      dat.full$title[i] <- "Noble"
    }
    else if(grepl("Capt|Col|Major",dat.full$title[i]) == T){
      dat.full$title[i] <- "Soldier"
    } 
    else{
      if(dat.full$Sex[i] == "male"){
        dat.full$title[i] <- "Mr"  
      } else{
        dat.full$title[i] <- "Miss"
      }
    }
  } 
}
dat.full$title <- as.factor(dat.full$title)

# factorize cabin variable according to letter
dat.full$Cabin <-sapply(dat.full$Cabin, function(x) substr(x,1,1))
dat.full$Cabin[dat.full$Cabin==""] <- NA
dat.full$Cabin <- as.factor(dat.full$Cabin)

# factorize embarked variable according to letter
dat.full$Embarked[dat.full$Embarked==""] <- NA
dat.full$Embarked <- as.factor(dat.full$Embarked)

# reduce factor size of ticket variable
dat.full$Ticket <- as.character(dat.full$Ticket)
dat.full$Ticket[grepl("L",dat.full$Ticket) == TRUE] <- "L"
dat.full$Ticket[grepl("F",dat.full$Ticket) == TRUE] <- "F"
dat.full$Ticket[grepl("PC|P",dat.full$Ticket) == TRUE] <- "P"
dat.full$Ticket[grepl("CA|C.A.|CA.|C ",dat.full$Ticket) == TRUE] <- "C"
dat.full$Ticket[grepl("A/5|A/5.|A.5.|A./5.|A/4.|A4.|A|A.|AQ",dat.full$Ticket) == TRUE] <- "A"
dat.full$Ticket[grepl("S",dat.full$Ticket) == TRUE] <- "S"
dat.full$Ticket[grepl("W",dat.full$Ticket) == TRUE] <- "W"
dat.full$Ticket <- sapply(dat.full$Ticket, function(x) ifelse(nchar(x)>1,as.character(nchar(x)),x))

 for (i in 1:length(dat.full$Ticket)) {
   if (dat.full$Ticket[i] == '3' || dat.full$Ticket[i] == '7' || dat.full$Ticket[i] == 'A' || dat.full$Ticket[i] == 'F' ||
       dat.full$Ticket[i] == 'L' || dat.full$Ticket[i] == 'W'){
     dat.full$Ticket[i] <- "Other"
       }
   
 }
dat.full$Ticket <- as.factor(dat.full$Ticket)


# Create family size variable including the passenger itself
dat.full <- transform(dat.full, 'familySize' =  SibSp + Parch +1)
dat.full <- dat.full[ , -which(names(dat.full) %in% c("SibSp","Parch"))]
dat.full$fSize <- NA
dat.full$fSize[dat.full$familySize == 1] <- 'singleton'
dat.full$fSize[dat.full$familySize <= 4 & dat.full$familySize > 1] <- 'small'
dat.full$fSize[dat.full$familySize > 4] <- 'large'
dat.full <- dat.full[ , -which(names(dat.full) %in% c("familySize"))]
dat.full$fSize <- as.factor(dat.full$fSize)

# Change sex variable to more understandable isMale variable
dat.full$isMale <- NA
dat.full$isMale[dat.full$Sex == "male"] <- 1
dat.full$isMale[dat.full$Sex <= "female"] <- 0
dat.full$isMale <- as.factor(dat.full$isMale)
dat.full <- dat.full[ , -which(names(dat.full) %in% c("Sex"))]

# Deleting the names variable
dat.full <- dat.full[ , -which(names(dat.full) %in% c("Name"))]
```

After getting rid of spaces in the character values and factorizing them as well as transforming the numerical variables, now let's look at the data summary.

```{r data summary}
summary(dat.full)
str(dat.full)
```

Cabin and age predictors have a lot of missing observations so it can be beneficial to get rid of these predictors but we will also be losing a lot of information so it makes sense to further investigate if imputation is possible.

```{r visual check with available data1}
dat.full.train <- data.frame(Survived = as.factor(dat.train[,2]),dat.full[1:891,])
g <- ggplot()
title_avAge <- dat.full.train %>% group_by(title) %>% summarise(n=n(),avAge = mean(Age, na.rm = T), 
                                                                medAge = median(Age,na.rm=T))
p1 <- g + geom_col(data = title_avAge,aes(x=title,y=avAge),fill = "deepskyblue3")
p2 <- g + geom_col(data = title_avAge,aes(x=title,y=n),fill = "salmon3")
grid.arrange(p1,p2, ncol=2)

survtitle1 <- g + geom_bar(data = dat.full.train, aes(x=title, fill = Survived), position = "stack")
survtitle2 <- g + geom_bar(data = dat.full.train, aes(x=title, fill = Survived), position = "fill")
grid.arrange(survtitle1,survtitle2, ncol=2)

ticket_avFare <- dat.full.train %>% group_by(Ticket) %>% summarise(n=n(),avFare = mean(Fare, na.rm = T))
g + geom_col(data = ticket_avFare,aes(x=Ticket,y=avFare),fill = "deepskyblue3")

survClass1 <- g + geom_bar(data = dat.full.train, aes(x=Pclass, fill = Survived), position = "stack")
survClass2 <- g + geom_bar(data = dat.full.train, aes(x=Pclass, fill = Survived), position = "fill")
grid.arrange(survClass1,survClass2, ncol=2)

Pclass_avFare <- dat.full.train %>% group_by(Pclass) %>% summarise(n=n(),avFare = mean(Fare, na.rm = T))
g + geom_col(data = Pclass_avFare,aes(x=Pclass,y=avFare),fill = "deepskyblue3")

survCabin1 <- g + geom_bar(data = dat.full.train, aes(x=Cabin, fill = Survived), position = "stack")
survCabin2 <- g + geom_bar(data = dat.full.train, aes(x=Cabin, fill = Survived), position = "fill")
grid.arrange(survCabin1,survCabin2, ncol=2)

survTicket1 <- g + geom_bar(data = dat.full.train, aes(x=Ticket, fill = Survived), position = "stack")
survTicket2 <- g + geom_bar(data = dat.full.train, aes(x=Ticket, fill = Survived), position = "fill")
grid.arrange(survTicket1,survTicket2, ncol=2)

g + geom_bar(data = dat.full.train, aes(x=Pclass, fill = Cabin), position = "stack")
g + geom_bar(data = dat.full.train, aes(x=Ticket, fill = Cabin), position = "stack")
g + geom_bar(data = dat.full.train, aes(x=Pclass, fill = Ticket), position = "stack")

survfSize1 <- g + geom_bar(data = dat.full.train, aes(x=fSize, fill = Survived), position = "stack")
survfSize2 <- g + geom_bar(data = dat.full.train, aes(x=fSize, fill = Survived), position = "fill")
grid.arrange(survfSize1,survfSize2, ncol=2)

survEmbarked1 <- g + geom_bar(data = dat.full.train, aes(x=Embarked, fill = Survived), position = "stack")
survEmbarked2 <- g + geom_bar(data = dat.full.train, aes(x=Embarked, fill = Survived), position = "fill")
grid.arrange(survEmbarked1,survEmbarked2, ncol=2)
```

We will impute the missing age observations by replacing them with median of each title group that the individual belongs to.

```{r visual check with available data2}
#Imputing the age variable
for (i in 1:length(dat.full$Age)){
  if(is.na(dat.full$Age[i])==T){
    if(dat.full$title[i] == "Master") dat.full$Age[i] = title_avAge[1,4]
    if(dat.full$title[i] == "Miss") dat.full$Age[i] = title_avAge[2,4]
    if(dat.full$title[i] == "Mr") dat.full$Age[i] = title_avAge[3,4]
    if(dat.full$title[i] == "Mrs") dat.full$Age[i] = title_avAge[4,4]
    if(dat.full$title[i] == "Noble") dat.full$Age[i] = title_avAge[5,4]
    if(dat.full$title[i] == "Soldier") dat.full$Age[i] = title_avAge[6,4]
  }
}
dat.full$Age <- as.numeric(dat.full$Age)

dat.full.train <- data.frame(Survived = as.factor(dat.train[,2]),dat.full[1:891,])
g + geom_boxplot(data = dat.full.train, aes(Survived, Age))
```

Individuals that are upper class passengers, are members of small families(2 to 4 family members), embarked from C and are below 60 years old tend to have higher survival rates. 

Cabin variable will be dropped as it doesn't seem possible to impute this predictor with lots of missing observations. However, it might still makes sense to impute age predictor.

```{r missing data}
dat.full <- dat.full[ , !(names(dat.full) %in% c("Cabin"))]
md.pattern(dat.full, rotate.names = TRUE)

imp_full <- mice(dat.full, m = 20, maxit = 40,printFlag = FALSE)
summary(imp_full)
imp_full$method
plot(imp_full)
dat.full_imp <- complete(imp_full)

# Log transform continuous age and fare variable
dat.full_imp$FareLog <- log(dat.full_imp$Fare+1) # 1 added to avoid log(0)
dat.full_imp$AgeLog <- log(dat.full_imp$Age+1) # 1 added to avoid log(0)
dat.full_imp <- dat.full_imp[ , -which(names(dat.full_imp) %in% c("Age","Fare"))]

train_imp <- data.frame(PassengerId = dat.full_imp[1:891,1], Survived = as.factor(dat.train[,2]), dat.full_imp[1:891,2:9])
test_imp <- dat.full_imp[892:1309,]
```

The imputed dataset will be used for analysis.

```{r model input}
y.train <- as.numeric(train_imp$Survived) # outcome
y.train <- y.train-1
pId.train <- train_imp$PassengerId # ID for predictions
pId.test <- test_imp$PassengerId # ID for predictions

predictor.variables <- colnames(train_imp)[3:length(colnames(train_imp))]
predictor1.variables <- predictor.variables[predictor.variables != "title"]
predictor2.variables <- predictor.variables[predictor.variables != "Pclass"]
predictor3.variables <- predictor.variables[predictor.variables != "Ticket"]
predictor4.variables <- predictor.variables[predictor.variables != "Embarked"]
predictor5.variables <- predictor.variables[predictor.variables != "fSize"]

formula_train <- as.formula(y.train~ .)
formula_test <- as.formula(~ .)

X <- subset(train_imp, select=predictor1.variables)
X1.train <- model.matrix(formula_train, data = X)[,-1]
X <- subset(test_imp, select=predictor1.variables)
X1.test <- model.matrix(formula_test, data = X)[,-1]

X <- subset(train_imp, select=predictor2.variables)
X2.train <- model.matrix(formula_train, data = X)[,-1]
X <- subset(test_imp, select=predictor2.variables)
X2.test <- model.matrix(formula_test, data = X)[,-1]

X <- subset(train_imp, select=predictor3.variables)
X3.train <- model.matrix(formula_train, data = X)[,-1]
X <- subset(test_imp, select=predictor3.variables)
X3.test <- model.matrix(formula_test, data = X)[,-1]

X <- subset(train_imp, select=predictor4.variables)
X4.train <- model.matrix(formula_train, data = X)[,-1]
X <- subset(test_imp, select=predictor4.variables)
X4.test <- model.matrix(formula_test, data = X)[,-1]

X <- subset(train_imp, select=predictor5.variables)
X5.train <- model.matrix(formula_train, data = X)[,-1]
X <- subset(test_imp, select=predictor5.variables)
X5.test <- model.matrix(formula_test, data = X)[,-1]

colnames(X1.train) <- gsub(" ", "", colnames(X1.train), fixed = TRUE)
colnames(X1.test) <- gsub(" ", "", colnames(X1.test), fixed = TRUE)
colnames(X2.train) <- gsub(" ", "", colnames(X2.train), fixed = TRUE)
colnames(X2.test) <- gsub(" ", "", colnames(X2.test), fixed = TRUE)
colnames(X3.train) <- gsub(" ", "", colnames(X3.train), fixed = TRUE)
colnames(X3.test) <- gsub(" ", "", colnames(X3.test), fixed = TRUE)
colnames(X4.train) <- gsub(" ", "", colnames(X4.train), fixed = TRUE)
colnames(X4.test) <- gsub(" ", "", colnames(X4.test), fixed = TRUE)
colnames(X5.train) <- gsub(" ", "", colnames(X5.train), fixed = TRUE)
colnames(X5.test) <- gsub(" ", "", colnames(X5.test), fixed = TRUE)

X1.train <- scale(X1.train)
X1.test <- scale(X1.test)
X2.train <- scale(X2.train)
X2.test <- scale(X2.test)
X3.train <- scale(X3.train)
X3.test <- scale(X3.test)
X4.train <- scale(X4.train)
X4.test <- scale(X4.test)
X5.train <- scale(X5.train)
X5.test <- scale(X5.test)

titleTrain <- as.numeric(train_imp$title)
titleTest <- as.numeric(test_imp$title)

pClassTrain <- as.numeric(train_imp$Pclass)
pClassTest <- as.numeric(test_imp$Pclass)

ticketTrain <- as.numeric(train_imp$Ticket)
ticketTest <- as.numeric(test_imp$Ticket)

embarkedTrain <- as.numeric(train_imp$Embarked)
embarkedTest <- as.numeric(test_imp$Embarked)

fsizeTrain <- as.numeric(train_imp$fSize)
fsizeTest <- as.numeric(test_imp$fSize)
```

## 3- Prior Predictive Checking

We will perform a prior predictive check with only using the priors and no data.The reason for making prior predictive analysis is to make a sanity check on the priors without using the likelihood. 

```{r prior predictive checking}
# Prior predictive checks
title <- titleTrain
df1.train <- as.data.frame(cbind(y.train, X1.train,title))

formula_only_intercept_population <- as.formula(y.train ~ 1)
formula_only_intercept_population <- bf(formula = formula_only_intercept_population, center = F)

formula_only_intercept_population_and_group <- as.formula(y.train ~ 1 + (1|title))
formula_only_intercept_population_and_group <- bf(formula = formula_only_intercept_population_and_group, center = F)

formula_hier1_title <- as.formula(paste("y.train ~", paste0("1+",paste(colnames(df1.train)[2:(length(colnames(df1.train))-1)], collapse = "+")),"+(1+",paste(colnames(df1.train)[2:(length(colnames(df1.train))-1)], collapse = "+"),"|title)"))
formula_hier1_title <- bf(formula = formula_hier1_title, center = F)

prior0 <- prior(student_t(3,0,2.5), class = b)
prior1 <- prior(student_t(3,0,2.5), class = b) + prior(lkj(2), class = cor)

multi_hier1_title_prior.fit <- brm(formula = formula_hier1_title,
                                       data = df1.train,
                                       prior = prior1,
                                       sample_prior = "only",
                                       family = bernoulli(link="logit"),
                                       cores = parallel::detectCores(),
                                       control = list(adapt_delta = 0.98, max_treedepth = 15))

yrep.prior1 <- posterior_predict(multi_hier1_title_prior.fit)

pp_check(y.train, yrep.prior1, ppc_dens_overlay)
pp_check(y.train, yrep.prior1, fun = "stat_grouped", group = title, stat = "mean")
pp_check(y.train, yrep.prior1, ppc_bars)
pp_check(y.train, yrep.prior1, ppc_bars_grouped, group = title)
pp_check(y.train, yrep.prior1, ppc_rootogram)
pp_check(multi_hier1_title_prior.fit, type = "stat_2d")
pp_check(multi_hier1_title_prior.fit, type = "violin_grouped", group = "title")
```

We have used weakly informative robust prior of student_t(3,0,2.5) for both population-level and group-level parameters. We also used lkj(2) for the correlation matrix. It can be seen that the spread for prior predictive samples have much higher variance than the actual response variable for the training set. It confirms that the chosen prior can be used for posterior predictive check along with the likelihood.

## 4 - Model Fitting and Algorithm Diagnostics
```{r model fitting}
title <- titleTest
df1.test <- as.data.frame(cbind(X1.test,title))

# model 1: Only intercept model at population level----------------------------------------------------
only_population_intercept.fit <- brm(formula = formula_only_intercept_population,
                                      data = df1.train,
                                      prior = prior0,
                                      family = bernoulli(link="logit"),
                                      cores = parallel::detectCores(),
                                      control = list(adapt_delta = 0.98, max_treedepth = 15))

# model 2: Only intercept model at population level and grouping level by title------------------------
population_and_group_intercept.fit <- brm(formula = formula_only_intercept_population_and_group,
                                      data = df1.train,
                                      prior = prior0,
                                      family = bernoulli(link="logit"),
                                      cores = parallel::detectCores(),
                                      control = list(adapt_delta = 0.98, max_treedepth = 15))


# model 3: All predictors model with population and group effects by title----------------------------
multi_hier1_title_post.fit <- brm(formula = formula_hier1_title,
                                       data = df1.train,
                                       prior = prior1,
                                       family = bernoulli(link="logit"),
                                       cores = parallel::detectCores(),
                                       control = list(adapt_delta = 0.98, max_treedepth = 15))


```


```{r simulating posterior predictions}
# making predictions
y_pred1 <- posterior_predict(only_population_intercept.fit, df1.test)
y_pred2 <- posterior_predict(population_and_group_intercept.fit, df1.test)
y_pred3 <- posterior_predict(multi_hier1_title_post.fit, df1.test)

yrep1.posterior <- posterior_predict(only_population_intercept.fit)
yrep2.posterior <- posterior_predict(population_and_group_intercept.fit)
yrep3.posterior <- posterior_predict(multi_hier1_title_post.fit)
```

## 5 - Posterior Predictive Checking
```{r posterior predictive checking}
summary(only_population_intercept.fit)
summary(population_and_group_intercept.fit)
summary(multi_hier1_title_post.fit)

plot(conditional_effects(multi_hier1_title_post.fit), ask = F)

round(posterior_interval(multi_hier1_title_post.fit, prob = 0.9), 2)

pp_check(y.train, yrep.posterior1, ppc_dens_overlay)
pp_check(y.train, yrep.posterior1, fun = "stat_grouped", group = title, stat = "mean")
pp_check(y.train, yrep.posterior1, ppc_bars)
pp_check(y.train, yrep.posterior1, ppc_bars_grouped, group = title)
pp_check(y.train, yrep.posterior1, ppc_rootogram)
pp_check(multi_hier1_title_post.fit_brms, type = "stat_2d")
pp_check(multi_hier1_title_post.fit_brms, type = "violin_grouped", group = "title")
pp_check(multi_hier1_title_post.fit_brms, type='error_scatter_avg')

mcmc_intervals(multi_hier1_title_post.fit, pars = c("b_Intercept",paste0("b_",colnames(df1.train)[2:(length(colnames(df1.train))-1)])))

mcmc_areas(multi_hier1_title_post.fit, pars = c("b_Intercept",paste0("b_",colnames(df1.train)[2:(length(colnames(df1.train))-1)])))

mcmc_hist(multi_hier1_title_post.fit_brms, pars = c("b_Intercept",paste0("b_",colnames(df1.train)[2:(length(colnames(df1.train))-1)])))
```

## 6 - Model Comparison
```{r model comparison}
loo1 <- loo::loo(only_population_intercept.fit, save_psis = TRUE, cores = 4)
loo2 <- loo::loo(population_and_group_intercept.fit, save_psis = TRUE, cores = 4)
loo3 <- loo::loo(multi_hier1_title_post.fit, save_psis = TRUE, cores = 4)

print(loo1)
print(loo2)
print(loo3)

plot(loo1, label_points = TRUE)
plot(loo2, label_points = TRUE)
plot(loo3, label_points = TRUE)

loo::loo_compare(loo1,loo2,loo3)

# Marginal Posterior Predictive Checks
ppc_loo_pit_overlay(
  y = y.train,
  yrep = yrep1.posterior,
  lw = weights(loo1$psis_object)
)

ppc_loo_pit_overlay(
  y = y.train,
  yrep = yrep2.posterior,
  lw = weights(loo2$psis_object)
)

ppc_loo_pit_overlay(
  y = y.train,
  yrep = yrep3.posterior,
  lw = weights(loo3$psis_object)
)
```

## 7 - Prediction Submission
```{r predictions model1}
probs1.hier <- apply(y_pred1.hier, 2, mean)
preds1.hier <- ifelse(probs1.hier > .5, 1, 0)

model1_hier.submission <- data.frame("PassengerId" = pId.test, "Survived" = preds1.hier)
write.csv(x = model1_hier.submission, file = file.path("C:","Users","alpgu","Dropbox","Data Science",                                             "Bayesian Data Analysis","BDA3 (Gelman)","titanic","submissions","model1_hier_title.csv"),
          row.names = FALSE)
```
